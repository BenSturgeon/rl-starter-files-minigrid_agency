{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18890687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "Environment loaded\n",
      "\n",
      "Agent loaded\n",
      "\n",
      "Saving gif 0decisions.gif of 2800 length \n",
      "Done.\n",
      "Saving gif 1decisions.gif of 2800 length \n",
      "Done.\n",
      "Saving gif 2decisions.gif of 2800 length \n",
      "Done.\n",
      "Saving gif 3decisions.gif of 2800 length \n",
      "Done.\n",
      "Saving gif 4decisions.gif of 2800 length \n",
      "Done.\n",
      "Saving gif 5decisions.gif of 2800 length \n",
      "Done.\n",
      "Saving gif 6decisions.gif of 2800 length \n",
      "Done.\n",
      "Saving gif 7decisions.gif of 2800 length \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import json\n",
    "import utils\n",
    "from utils import device\n",
    "import hashlib\n",
    "import torch\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "def add_count_to_frame(frame):\n",
    "    global frame_count\n",
    "\n",
    "    # Increment the frame count\n",
    "    frame_count += 1\n",
    "\n",
    "    # Add count number to the top left corner\n",
    "    count_text = str(frame_count)\n",
    "    position = (10, 20)\n",
    "    color = (255, 0, 0)\n",
    "    thickness = 2\n",
    "    font_scale = 0.8\n",
    "    cv2.putText(frame, count_text, position, cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "    # Convert the frame to PIL Image\n",
    "    image = Image.fromarray(frame)\n",
    "\n",
    "    # Convert the image to a quantized version with 256 colors\n",
    "    quantized_image = image.quantize(colors=256)\n",
    "\n",
    "    # Convert the quantized image back to 'RGB' mode\n",
    "    quantized_image_rgb = quantized_image.convert('RGB')\n",
    "\n",
    "    # Convert the RGB image back to a NumPy array\n",
    "    quantized_frame = np.array(quantized_image_rgb)\n",
    "\n",
    "    # cv2.imshow(\"quantized_frame\", quantized_frame)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    # No need to convert to BGR as it's already in RGB format\n",
    "    return quantized_frame\n",
    "\n",
    "def hash_state(state):\n",
    "    state_string = pickle.dumps(state.grid)\n",
    "    return hashlib.sha256(state_string).hexdigest()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hash_grid(env):\n",
    "    # Retrieve the grid\n",
    "    grid = env.grid.encode()\n",
    "\n",
    "    # Retrieve the agent's position and direction\n",
    "    agent_pos = env.agent_pos\n",
    "    agent_dir = env.agent_dir\n",
    "\n",
    "    # Flatten the grid and convert to string\n",
    "    grid_string = ''.join(str(cell) for row in grid for cell in row)\n",
    "\n",
    "    # Add the agent's position and direction to the string\n",
    "    state_string = f'{grid_string},{agent_pos},{agent_dir}'\n",
    "    \n",
    "    print(agent_pos, agent_dir)\n",
    "    # Hash the string\n",
    "    return hashlib.sha256(state_string.encode('utf-8')).hexdigest()\n",
    "\n",
    "def depth_first_search(env, agent, depth):\n",
    "    if depth == 0:\n",
    "        return [hash_state(env)]\n",
    "    \n",
    "    next_states = get_next_states(env, agent)\n",
    "\n",
    "    # for each of the next states, get their next states and append them to all_states\n",
    "    all_states = []\n",
    "\n",
    "    for new_env in next_states:\n",
    "        all_states.extend(depth_first_search(new_env, agent, depth=depth-1))\n",
    "    \n",
    "    return all_states\n",
    "\n",
    "def get_next_states(env, agent):\n",
    "    \"\"\"\n",
    "    Returns all possible next states given current state\n",
    "    \"\"\"\n",
    "    # find all possible actions\n",
    "    action_space = env.action_space.n\n",
    "\n",
    "    # initialize next_states list\n",
    "    saved_env = pickle.dumps(env)\n",
    "    next_envs = []\n",
    "    # get next state for each action\n",
    "    for action in range(action_space):\n",
    "        # we load the original state\n",
    "        old_env = pickle.loads(saved_env) \n",
    "        obs_new, _, _, _, _ = old_env.step(action) # The new env gets created and svaed\n",
    "        next_envs.append(old_env)\n",
    "\n",
    "        if gif:\n",
    "            frame = old_env.get_frame()\n",
    "            frame = add_count_to_frame(frame)\n",
    "            frames.append(frame)\n",
    "\n",
    "    \n",
    "    return set(next_envs)\n",
    "\n",
    "\n",
    "frames = []\n",
    "# Replace command line arguments with hard-coded values.\n",
    "env_name = \"MiniGrid-DoorKey-5x5-v0\"\n",
    "model_name = \"DoorKeya2c\"\n",
    "seed = 0\n",
    "shift = 0\n",
    "argmax = False\n",
    "pause = 0.1\n",
    "gif = True\n",
    "episodes = 1\n",
    "memory = False\n",
    "text = False\n",
    "\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(seed)\n",
    "\n",
    "# Set device\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "# Load environment\n",
    "env = utils.make_env(env_name, seed)\n",
    "for _ in range(shift):\n",
    "    env.reset()\n",
    "print(\"Environment loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "agent = utils.Agent(env.observation_space, env.action_space, model_dir,\n",
    "                    argmax=argmax, use_memory=memory, use_text=text)\n",
    "print(\"Agent loaded\\n\")\n",
    "\n",
    "# Run the agent\n",
    "if gif:\n",
    "    from array2gif import write_gif\n",
    "    frames = []\n",
    "\n",
    "for episode in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "    cycle = 0\n",
    "\n",
    "    while True:\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "        next_states = depth_first_search(env, agent, depth=4)\n",
    "        if gif:\n",
    "            \n",
    "            print(f\"Saving gif {str(cycle) + 'decisions.gif'} of {len(frames)} length \\n\", end=\"\")\n",
    "            pil_images = [Image.fromarray(frame) for frame in frames]\n",
    "            pil_images[0].quantize(colors=256).save(str(cycle) + 'decisions.gif', save_all=True, append_images=[pil_img.quantize(colors=256) for pil_img in pil_images[1:]], optimize=False, duration=30, loop=0)\n",
    "            # write_gif(numpy.array(frames), str(cycle) +\"decisions.gif\", fps=2/pause)\n",
    "            print(\"Done.\")\n",
    "            frames =[]\n",
    "            cycle+=1\n",
    "            frame_count = 0\n",
    "        \n",
    "\n",
    "        done = terminated | truncated\n",
    "        agent.analyze_feedback(reward, done)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if gif:\n",
    "#     print(\"Saving gif... \", end=\"\")\n",
    "#     write_gif(numpy.array(frames), gif+\".gif\", fps=1/pause)\n",
    "#     print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15467a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def copy_environment(env):\n",
    "    # Create a new environment with the same grid size and type\n",
    "    new_env = utils.make_env(env_name, seed, render_mode=\"human\")\n",
    "    \n",
    "    # Copy the grid state\n",
    "    new_env.grid = env.grid.encode()\n",
    "    \n",
    "    # Retrieve the agent's position and direction\n",
    "    agent_pos = env.agent_pos\n",
    "    agent_dir = env.agent_dir\n",
    "    \n",
    "    # Set the agent's position and direction in the new environment\n",
    "    new_env.agent_pos = agent_pos\n",
    "    new_env.agent_dir = agent_dir\n",
    "    \n",
    "    return new_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a383d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_85053/3382915127.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m agent = utils.Agent(env.observation_space, env.action_space, model_dir,\n\u001b[1;32m     13\u001b[0m                     argmax=argmax, use_memory=memory, use_text=text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "env = utils.make_env(env_name, seed, render_mode=\"human\")\n",
    "for _ in range(shift):\n",
    "    env.reset()\n",
    "\n",
    "# env2.grid = env.grid\n",
    "\n",
    "# image_data = env.get_frame()\n",
    "# plt.imshow(image_data)\n",
    "# plt.show()\n",
    "        \n",
    "model_dir = utils.get_model_dir(model)\n",
    "agent = utils.Agent(env.observation_space, env.action_space, model_dir,\n",
    "                    argmax=argmax, use_memory=memory, use_text=text)\n",
    "print(\"Agent loaded\\n\")\n",
    "\n",
    "# Run the agent\n",
    "\n",
    "if gif:\n",
    "    from array2gif import write_gif\n",
    "\n",
    "    frames = []\n",
    "\n",
    "# Create a window to view the environment\n",
    "env.render()\n",
    "\n",
    "for episode in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "    while True:\n",
    "        env.render()\n",
    "        if gif:\n",
    "            frames.append(numpy.moveaxis(env.get_frame(), 2, 0))\n",
    "\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated | truncated\n",
    "        agent.analyze_feedback(reward, done)\n",
    "\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516dcbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_copy2 = env.grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6ab2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d272dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_copy2.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba68f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_copy.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03982567",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = agent.get_action(obs)\n",
    "obs, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "# next_states now contains a dictionary of possible states at t+1, t+2, etc.        \n",
    "next_states =  depth_first_search(env, obs, agent, depth=3)\n",
    "print(len(next_states))\n",
    "\n",
    "done = terminated | truncated\n",
    "agent.analyze_feedback(reward, done)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506afff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for episode in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "#     while True:\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grid_world_kernel",
   "language": "python",
   "name": "minigrid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
